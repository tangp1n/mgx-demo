"""App creator agent using LangGraph."""
import asyncio
from typing import AsyncIterator, Dict, Any
from langgraph.graph import StateGraph, END
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage

from .llm_config import get_llm
from .state import AgentState, ConversationStage
from ...utils.sse_formatter import SSEFormatter
from ...utils.logger import get_logger

logger = get_logger("app_creator.agent")


class AppCreatorAgent:
    """Agent for handling app creation conversations."""

    def __init__(self):
        """Initialize the app creator agent."""
        self.llm = get_llm()
        self.sse_formatter = SSEFormatter()
        self.graph = self._build_graph()

    def _build_graph(self) -> StateGraph:
        """
        Build the LangGraph state machine for app creation.

        Returns:
            Compiled state graph
        """
        workflow = StateGraph(AgentState)

        # Add only route_entry node - it handles all logic in one LLM call
        workflow.add_node("route_entry", self._route_entry_node)

        # Set entry point
        workflow.set_entry_point("route_entry")

        # route_entry always ends after processing (response already sent)
        workflow.add_edge("route_entry", END)

        # Compile with increased recursion limit
        return workflow.compile()

    async def _route_entry_node(self, state: AgentState) -> Dict[str, Any]:
        """
        Smart entry routing node that uses LLM to analyze conversation history,
        determine current state, and generate appropriate response.

        Args:
            state: Current agent state

        Returns:
            Updated state with action decision and AI response
        """
        requirements_confirmed = state.get('requirements_confirmed', False)
        existing_requirements = state.get('requirements')
        existing_questions = state.get('clarifying_questions')

        logger.info(f"üö™ [route_entry] requirements_confirmed={requirements_confirmed}, has_requirements={bool(existing_requirements)}, questions={len(existing_questions) if existing_questions else 0}")

        # If already confirmed, end immediately
        if requirements_confirmed:
            logger.info("‚úÖ [route_entry] Already confirmed -> END")
            return state

        # Build system prompt for LLM to analyze and decide
        system_prompt = """‰Ω†ÊòØ‰∏Ä‰∏™Â∏ÆÂä©Áî®Êà∑ÈÄöËøáÂØπËØùÂàõÂª∫Â∫îÁî®ÁöÑAIÂä©Êâã„ÄÇ

‰Ω†ÁöÑ‰ªªÂä°ÔºöÂàÜÊûêÂΩìÂâçÂØπËØùÂéÜÂè≤ÔºåÂà§Êñ≠ÂΩìÂâçÁä∂ÊÄÅÔºåÂπ∂ÂÜ≥ÂÆö‰∏ã‰∏ÄÊ≠•Ë°åÂä®ÔºåÂêåÊó∂ÁîüÊàêÂêàÈÄÇÁöÑÂõûÂ§ç„ÄÇ

**ÈáçË¶ÅËßÑÂàô**Ôºö
- ‰Ω†Âè™Ë¥üË¥£ÈúÄÊ±ÇÊî∂ÈõÜÂíåÁ°ÆËÆ§Ôºå‰∏çË¥üË¥£‰ª£Á†ÅÁîüÊàê
- ÁªùÂØπ‰∏çË¶ÅÁîüÊàê‰ªª‰Ωï‰ª£Á†ÅÊàñ‰ª£Á†ÅÁ§∫‰æã
- ‰∏ìÊ≥®‰∫éÁêÜËß£Áî®Êà∑ÁöÑÂ∫îÁî®ÈúÄÊ±Ç

**ÂèØËÉΩÁöÑË°åÂä®Á±ªÂûã**Ôºö

1. **clarify** - ÈúÄË¶ÅÊæÑÊ∏ÖÈóÆÈ¢ò
   - ÂΩìÈúÄÊ±ÇÂ≠òÂú®Ê†πÊú¨ÊÄßÊ®°Á≥äÔºà‰ºöÂÆåÂÖ®ÈòªÁ¢çÂÆûÊñΩÔºâÊó∂
   - ‰ø°ÊÅØ‰∏çÂÖ®ÔºåÈúÄË¶ÅÊæÑÊ∏Ö
   - ÊúÄÂ§öÂè™ÈóÆ1‰∏™ÊúÄÂÖ≥ÈîÆÁöÑÈóÆÈ¢ò
   - ÁîüÊàêÊæÑÊ∏ÖÈóÆÈ¢òÁöÑÂõûÂ§ç

2. **extract** - ÊèêÂèñÈúÄÊ±ÇÂπ∂Á°ÆËÆ§
   - ÂΩìÂØπËØù‰∏≠Â∑≤ÁªèÊî∂ÈõÜÂà∞Ë∂≥Â§üÁöÑ‰ø°ÊÅØÊù•ÁêÜËß£Â∫îÁî®ÈúÄÊ±ÇÊó∂
   - ‰ø°ÊÅØÂ∑≤ÂÖ®ÔºåÂΩìÂú∫ÊèêÂèñÈúÄÊ±Ç
   - ‰ªéÂØπËØù‰∏≠ÊèêÂèñÂπ∂ÁªìÊûÑÂåñÈúÄÊ±Ç
   - ÁîüÊàêÂõûÂ§çÔºåÂêëÁî®Êà∑Á°ÆËÆ§ÊòØÂê¶Ë¶ÅÂºÄÂßãÂàõÂª∫Â∫îÁî®
   - ËøôÊòØÊèêÂèñÂíåÁ°ÆËÆ§ÁöÑÂêàÂπ∂Êìç‰Ωú

3. **start_gen** - ÂºÄÂßã‰ª£Á†ÅÁîüÊàê
   - ÂΩìÈúÄÊ±ÇÂ∑≤ÁªèÊèêÂèñÔºåÁî®Êà∑ÊòéÁ°ÆÁ°ÆËÆ§Ë¶ÅÂºÄÂßãÊó∂‰ΩøÁî®
   - Áî®Êà∑Â∑≤ÁªèÁ°ÆËÆ§‰∫ÜË¶ÅÂºÄÂßãÔºåËß¶ÂèëÂêéÁª≠ÁöÑ‰ª£Á†ÅÁîüÊàêÊµÅÁ®ã
   - Áî®Êà∑ÂõûÂ§çÂåÖÂê´Á°ÆËÆ§ÂÖ≥ÈîÆËØçÔºàÂ¶Ç"Á°ÆËÆ§"„ÄÅ"ÊòØÁöÑ"„ÄÅ"ÂèØ‰ª•"„ÄÅ"ÂºÄÂßã"„ÄÅ"Â•ΩÁöÑ"„ÄÅ"ok"Á≠âÔºâÊó∂‰ΩøÁî®
   - ÁîüÊàêÁ°ÆËÆ§Ê∂àÊÅØÔºåË°®Á§∫Âç≥Â∞ÜÂºÄÂßãÊûÑÂª∫

4. **continue** - ÁªßÁª≠ÂØπËØù
   - ÂΩìÈúÄË¶ÅÊõ¥Â§ö‰ø°ÊÅØÊù•ÁêÜËß£Áî®Êà∑ÈúÄÊ±ÇÊó∂
   - ÁªßÁª≠‰∏éÁî®Êà∑ÂØπËØùÔºåÊî∂ÈõÜÊõ¥Â§ö‰ø°ÊÅØ

**Âà§Êñ≠ÈÄªËæë**Ôºö
- Â¶ÇÊûúÂ∑≤ÊúâÈúÄÊ±Ç‰∏îÁî®Êà∑Ê∂àÊÅØÂåÖÂê´Á°ÆËÆ§ÂÖ≥ÈîÆËØçÔºàÁ°ÆËÆ§„ÄÅÊòØÁöÑ„ÄÅÂèØ‰ª•„ÄÅÂºÄÂßã„ÄÅÂ•ΩÁöÑ„ÄÅok„ÄÅokay„ÄÅyesÁ≠âÔºâÔºå‰ΩøÁî® **start_gen**
- Â¶ÇÊûúÂ∑≤ÊúâÈúÄÊ±Ç‰ΩÜÁî®Êà∑Êú™Á°ÆËÆ§Ôºå‰ΩøÁî® **extract** Êù•ÊèêÂèñÂπ∂ËØ¢ÈóÆÁ°ÆËÆ§
- Â¶ÇÊûú‰ø°ÊÅØ‰∏çÂÖ®Ôºå‰ΩøÁî® **clarify** Êàñ **continue**

**ËæìÂá∫Ê†ºÂºèÔºàÂøÖÈ°ªÊòØÊúâÊïàÁöÑJSONÔºâ**Ôºö
{{
  "action": "clarify" | "extract" | "start_gen" | "continue",
  "response": "AIÁöÑÂõûÂ§çÊñáÊú¨Ôºà‰∏≠ÊñáÔºâ",
  "requirements": "Â¶ÇÊûúactionÊòØextractÊàñstart_genÔºåËøôÈáåÊòØÊèêÂèñÁöÑÈúÄÊ±ÇÊñáÊú¨Ôºà‰∏≠ÊñáÔºâÔºåÂê¶Âàô‰∏∫null",
  "clarifying_questions": ["Â¶ÇÊûúactionÊòØclarifyÔºåËøôÈáåÊòØÈóÆÈ¢òÂàóË°®ÔºàÊúÄÂ§ö1‰∏™ÔºâÔºåÂê¶Âàô‰∏∫[]"]
}}

**ÂΩìÂâçÁä∂ÊÄÅ‰ø°ÊÅØ**Ôºö
- Â∑≤ÊúâÈúÄÊ±Ç: {has_requirements}
- Â∑≤ÊúâÊæÑÊ∏ÖÈóÆÈ¢ò: {has_questions}

**ÈáçË¶Å**ÔºöËØ∑‰∏•Ê†ºÊåâÁÖßJSONÊ†ºÂºèËæìÂá∫Ôºå‰∏çË¶ÅÊ∑ªÂä†‰ªª‰ΩïÈ¢ùÂ§ñÁöÑÊñáÊú¨ÊàñËØ¥Êòé„ÄÇ""".format(
            has_requirements="ÊòØ" if existing_requirements else "Âê¶",
            has_questions="ÊòØ" if existing_questions else "Âê¶"
        )

        # Build messages for LLM
        messages = [SystemMessage(content=system_prompt)] + state["messages"]

        # Get LLM response
        logger.info("ü§ñ [route_entry] Calling LLM to analyze conversation and decide action...")
        response = await asyncio.to_thread(self.llm.invoke, messages)
        logger.info(f"‚úÖ [route_entry] LLM response received ({len(response.content)} chars)")

        # Parse LLM response (expecting JSON)
        import json
        import re

        action = "continue"
        ai_response = ""
        extracted_requirements = None
        clarifying_questions = None

        try:
            # Try to extract JSON from response
            content = response.content.strip()

            # Remove markdown code blocks if present
            content = re.sub(r'```json\s*', '', content)
            content = re.sub(r'```\s*', '', content)
            content = content.strip()

            # Try to find JSON object
            # First, try parsing the entire content
            try:
                result = json.loads(content)
                action = result.get("action", "continue")
                ai_response = result.get("response", "")
                extracted_requirements = result.get("requirements")
                clarifying_questions = result.get("clarifying_questions", [])
            except json.JSONDecodeError:
                # If that fails, try to extract JSON block
                json_match = re.search(r'\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}', content, re.DOTALL)
                if json_match:
                    json_str = json_match.group(0)
                    result = json.loads(json_str)
                    action = result.get("action", "continue")
                    ai_response = result.get("response", "")
                    extracted_requirements = result.get("requirements")
                    clarifying_questions = result.get("clarifying_questions", [])
                else:
                    # If no JSON found, treat entire response as text and default to continue
                    ai_response = content
                    logger.warning("‚ö†Ô∏è  [route_entry] No JSON found in LLM response, using as text response")

        except (json.JSONDecodeError, KeyError) as e:
            logger.error(f"‚ùå [route_entry] Failed to parse LLM response: {e}, content: {response.content[:200]}")
            # Fallback: use response as text
            ai_response = response.content
            action = "continue"

        logger.info(f"üéØ [route_entry] LLM decided action: {action}")

        # Update state based on action
        updated_state = {**state}
        new_messages = state["messages"].copy()

        if action == "clarify":
            # Need to clarify - ‰ø°ÊÅØ‰∏çÂÖ®ÔºåÈúÄË¶ÅÊæÑÊ∏Ö
            if ai_response:
                new_messages.append(AIMessage(content=ai_response))
            updated_state["clarifying_questions"] = clarifying_questions or []
            updated_state["current_stage"] = ConversationStage.CLARIFYING
            logger.info(f"‚ùì [route_entry] Action: clarify, questions: {clarifying_questions}")

        elif action == "extract":
            # Extract requirements - ‰ø°ÊÅØÂ∑≤ÂÖ®ÔºåÂΩìÂú∫ÊèêÂèñÔºåÂπ∂ÂêëÁî®Êà∑Á°ÆËÆ§ÊòØÂê¶Ë¶ÅÂºÄÂßã
            if extracted_requirements:
                updated_state["requirements"] = extracted_requirements
                logger.info(f"üìã [route_entry] Extracted requirements ({len(extracted_requirements)} chars)")
            if ai_response:
                new_messages.append(AIMessage(content=ai_response))
            # After extraction, ask user to confirm if they want to start
            updated_state["current_stage"] = ConversationStage.CONFIRMING
            updated_state["clarifying_questions"] = []
            logger.info("üìã [route_entry] Extracted requirements, asking for confirmation")

        elif action == "start_gen":
            # Start generation - Áî®Êà∑Â∑≤ÁªèÁ°ÆËÆ§‰∫ÜË¶ÅÂºÄÂßãÔºåËß¶ÂèëÂêéÁª≠ÁöÑ‰ª£Á†ÅÁîüÊàêÊµÅÁ®ã
            if extracted_requirements:
                updated_state["requirements"] = extracted_requirements
                logger.info(f"üìã [route_entry] Updated requirements ({len(extracted_requirements)} chars)")
            if ai_response:
                new_messages.append(AIMessage(content=ai_response))
            # User confirmed, set confirmed and trigger code generation
            updated_state["requirements_confirmed"] = True
            updated_state["current_stage"] = ConversationStage.CONFIRMED
            updated_state["clarifying_questions"] = []
            logger.info("‚úÖ [route_entry] User confirmed, starting code generation")

        else:  # continue
            # Continue conversation - ÈúÄË¶ÅÊõ¥Â§ö‰ø°ÊÅØÊù•ÁêÜËß£Áî®Êà∑ÈúÄÊ±Ç
            if ai_response:
                new_messages.append(AIMessage(content=ai_response))
            updated_state["current_stage"] = ConversationStage.GATHERING
            logger.info("üí¨ [route_entry] Continue conversation")

        updated_state["messages"] = new_messages
        return updated_state

    async def stream_conversation(
        self,
        application_id: str,
        user_id: str,
        user_message: str,
        existing_messages: list = None,
        app_service=None
    ) -> AsyncIterator[str]:
        """
        Stream conversation events as SSE.

        Args:
            application_id: Application ID
            user_id: User ID
            user_message: User's message
            existing_messages: Existing conversation messages
            app_service: Application service for updating database (optional)

        Yields:
            SSE formatted events
        """
        try:
            # Initialize state
            messages = existing_messages or []
            messages.append(HumanMessage(content=user_message))

            # Try to restore state from database if app_service is provided
            requirements = None
            requirements_confirmed = False
            current_stage = ConversationStage.GATHERING
            clarifying_questions = None

            if app_service:
                try:
                    # Yield control before await to prevent blocking in nested async generators
                    await asyncio.sleep(0)
                    app = await app_service.get(application_id=application_id, user_id=user_id)
                    if app:
                        requirements = app.requirements
                        requirements_confirmed = app.requirements_confirmed
                        # Determine stage based on state
                        if requirements_confirmed:
                            current_stage = ConversationStage.CONFIRMED
                        elif requirements:
                            # Check if we've asked clarifying questions by looking at messages
                            # For now, assume no questions if requirements exist
                            clarifying_questions = []
                            current_stage = ConversationStage.CLARIFYING
                        else:
                            current_stage = ConversationStage.GATHERING
                        logger.info(f"üì¶ [stream] Restored state: requirements={bool(requirements)}, confirmed={requirements_confirmed}, stage={current_stage}")
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è  [stream] Failed to restore state from database: {e}")

            state = AgentState(
                messages=messages,
                application_id=application_id,
                user_id=user_id,
                requirements=requirements,
                requirements_confirmed=requirements_confirmed,
                clarifying_questions=clarifying_questions,
                current_stage=current_stage,
                error=None
            )

            # Yield thought event
            yield self.sse_formatter.format_thought("Processing your message...")

            # Track final state to get the last response
            final_state = None
            initial_message_count = len(state.get("messages", []))

            # Run the graph with config to increase recursion limit
            config = {"recursion_limit": 50}  # Increase from default 25

            # Run the graph
            logger.info(f"üöÄ [stream] Starting graph execution (stage: {state.get('current_stage')}, messages: {len(state.get('messages', []))})")

            last_sent_message_count = initial_message_count  # Track how many messages we've already sent
            sent_message_hashes = set()  # Track sent message content hashes to avoid duplicates

            async for event in self.graph.astream(state, config=config):
                # Yield control to event loop to prevent blocking in nested async generators
                await asyncio.sleep(0)

                # Extract node name and state
                node_name = list(event.keys())[0]
                node_state = event[node_name]

                logger.info(f"üîÑ [graph] Executed node: {node_name}")

                # Update final state (keep the latest state)
                final_state = node_state

                # Yield thought events for processing
                if node_name == "route_entry":
                    logger.info("üö™ [stream] Entry routing completed")

                    # Send AI response if generated
                    current_messages = node_state.get("messages", [])
                    if current_messages and len(current_messages) > last_sent_message_count:
                        new_messages = current_messages[last_sent_message_count:]
                        for message in new_messages:
                            if isinstance(message, AIMessage):
                                msg_hash = hash(message.content)
                                if msg_hash not in sent_message_hashes:
                                    yield self.sse_formatter.format_text(message.content)
                                    sent_message_hashes.add(msg_hash)
                        last_sent_message_count = len(current_messages)

                    # Check if requirements were extracted
                    if node_state.get("requirements") and not state.get("requirements"):
                        requirements = node_state.get("requirements")
                        logger.info(f"üìã [route_entry] Requirements extracted ({len(requirements)} chars)")

                        # Update database
                        if app_service:
                            try:
                                from ...models.application import ApplicationUpdate
                                # Yield control before await to prevent blocking
                                await asyncio.sleep(0)
                                await app_service.update(
                                    application_id=application_id,
                                    user_id=user_id,
                                    data=ApplicationUpdate(requirements=requirements)
                                )
                                logger.info(f"üíæ [route_entry] Updated requirements in database")

                                # Write requirements to container immediately when extracted (no need to wait for confirmation)
                                try:
                                    from ...services.container.container_lifecycle import ContainerLifecycleService

                                    # Get database connection from app_service
                                    db = app_service.db
                                    container_lifecycle = ContainerLifecycleService(db)
                                    # Yield control before await to prevent blocking
                                    await asyncio.sleep(0)
                                    await container_lifecycle.write_task_file(
                                        application_id=application_id,
                                        requirements=requirements
                                    )
                                    logger.info(f"üìù [route_entry] Wrote requirements to container for application {application_id}")
                                except Exception as e:
                                    logger.error(f"‚ùå [route_entry] Failed to write requirements to container: {e}", exc_info=True)
                            except Exception as e:
                                logger.error(f"‚ùå [route_entry] Failed to update requirements: {e}", exc_info=True)

                    # Check if requirements were confirmed
                    if node_state.get('requirements_confirmed', False):
                        logger.info("‚úÖ [stream] Requirements confirmed in route_entry")

                        # Update database if app_service is provided
                        if app_service:
                            requirements = node_state.get("requirements")
                            if requirements:
                                try:
                                    # Yield control before await to prevent blocking
                                    await asyncio.sleep(0)
                                    await app_service.confirm_requirements(
                                        application_id=application_id,
                                        user_id=user_id
                                    )
                                    from ...models.application import ApplicationUpdate
                                    # Yield control before await to prevent blocking
                                    await asyncio.sleep(0)
                                    await app_service.update(
                                        application_id=application_id,
                                        user_id=user_id,
                                        data=ApplicationUpdate(requirements=requirements)
                                    )
                                    logger.info(f"üíæ [route_entry] Updated application {application_id} in database")

                                    # Requirements should already be written to container when extracted
                                    # But update it again in case requirements were updated during confirmation
                                    try:
                                        from ...services.container.container_lifecycle import ContainerLifecycleService

                                        # Get database connection from app_service
                                        db = app_service.db
                                        container_lifecycle = ContainerLifecycleService(db)
                                        # Yield control before await to prevent blocking
                                        await asyncio.sleep(0)
                                        await container_lifecycle.write_task_file(
                                            application_id=application_id,
                                            requirements=requirements
                                        )
                                        logger.info(f"üìù [route_entry] Updated requirements in container for application {application_id}")
                                    except Exception as e:
                                        logger.error(f"‚ùå [route_entry] Failed to update requirements in container: {e}", exc_info=True)
                                except Exception as e:
                                    logger.error(f"‚ùå [route_entry] Failed to update application: {e}", exc_info=True)

                        # Emit requirements_confirmed event
                        # This event will be detected by conversations.py to trigger code generation
                        yield self.sse_formatter.format_event({
                            "type": "requirements_confirmed",
                            "data": {
                                "requirements": node_state.get("requirements", ""),
                                "message": "Requirements confirmed, starting code generation..."
                            }
                        })


            # Send any remaining AI messages from the final state (should be none if confirmation_node ran)
            # This is a safety net for edge cases
            if final_state:
                final_messages = final_state.get("messages", [])
                if final_messages and len(final_messages) > last_sent_message_count:
                    logger.warning(f"‚ö†Ô∏è  [stream] Fallback: {len(final_messages) - last_sent_message_count} unsent messages")
                    new_messages = final_messages[last_sent_message_count:]
                    for message in new_messages:
                        if isinstance(message, AIMessage):
                            # Use content hash to avoid duplicates
                            msg_hash = hash(message.content)
                            if msg_hash not in sent_message_hashes:
                                yield self.sse_formatter.format_text(message.content)
                                sent_message_hashes.add(msg_hash)

            # Yield done event
            yield self.sse_formatter.format_done()

        except Exception as e:
            yield self.sse_formatter.format_error(str(e))
            yield self.sse_formatter.format_done()
